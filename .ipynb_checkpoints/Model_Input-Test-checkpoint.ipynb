{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a18e84ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d44677b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 models\n",
    "cleaf_model = YOLO('cleaf.pt')\n",
    "cdisease_model = YOLO('cdisease.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "507f7e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaf model classes: {0: 'arabica', 1: 'liberica', 2: 'robusta'}\n",
      "Cdisease model classes: {0: 'brown_eye_spot', 1: 'leaf_miner', 2: 'leaf_rust', 3: 'red_spider_mite'}\n"
     ]
    }
   ],
   "source": [
    "# Verify and print the class names\n",
    "print(\"Cleaf model classes:\", cleaf_model.names)\n",
    "print(\"Cdisease model classes:\", cdisease_model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ccfe74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_classify_coffee_disease(image_path, output_path=None, conf_threshold=0.25, iou_threshold=0.45, screen_width=1920, screen_height=1080):\n",
    "    \"\"\"\n",
    "    Detect and classify coffee diseases using both cleaf and cdisease models.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path (str): Path to the input image file.\n",
    "    - output_path (str, optional): Path to save the output image with bounding boxes.\n",
    "    - conf_threshold (float): Confidence threshold for predictions.\n",
    "    - iou_threshold (float): IOU threshold for non-max suppression.\n",
    "    - screen_width (int): Width of the screen for display purposes.\n",
    "    - screen_height (int): Height of the screen for display purposes.\n",
    "\n",
    "    Returns:\n",
    "    - img (numpy.ndarray): The image with bounding boxes drawn.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n",
    "\n",
    "    # Stage 1: Detect the coffee leaf\n",
    "    leaf_results = cleaf_model.predict(source=img, conf=conf_threshold, iou=iou_threshold, verbose=False)\n",
    "    if len(leaf_results) > 0:\n",
    "        leaf_boxes = leaf_results[0].boxes\n",
    "        if len(leaf_boxes) > 0:\n",
    "            for box in leaf_boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                confidence = box.conf[0].cpu().numpy()\n",
    "                class_id = int(box.cls[0].cpu().numpy())\n",
    "                class_name = cleaf_model.names[class_id]\n",
    "\n",
    "                # Draw the bounding box for the leaf\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "                label = f\"{class_name} {confidence:.2f}\"\n",
    "                put_label_on_image(img, label, x1, y1, screen_width)\n",
    "\n",
    "                # Stage 2: Detect the disease within the leaf region\n",
    "                leaf_roi = img[y1:y2, x1:x2]\n",
    "                disease_results = cdisease_model.predict(source=leaf_roi, conf=conf_threshold, iou=iou_threshold, verbose=False)\n",
    "                if len(disease_results) > 0:\n",
    "                    disease_boxes = disease_results[0].boxes\n",
    "                    if len(disease_boxes) > 0:\n",
    "                        for dbox in disease_boxes:\n",
    "                            dx1, dy1, dx2, dy2 = dbox.xyxy[0].cpu().numpy().astype(int)\n",
    "                            dconfidence = dbox.conf[0].cpu().numpy()\n",
    "                            dclass_id = int(dbox.cls[0].cpu().numpy())\n",
    "                            dclass_name = cdisease_model.names[dclass_id]\n",
    "\n",
    "                            # Adjust disease box coordinates to match the original image\n",
    "                            dx1 += x1\n",
    "                            dy1 += y1\n",
    "                            dx2 += x1\n",
    "                            dy2 += y1\n",
    "\n",
    "                            # Draw the bounding box for the disease\n",
    "                            cv2.rectangle(img, (dx1, dy1), (dx2, dy2), color=(255, 0, 0), thickness=2)\n",
    "                            dlabel = f\"{dclass_name} {dconfidence:.2f}\"\n",
    "                            put_label_on_image(img, dlabel, dx1, dy1, screen_width)\n",
    "\n",
    "    # Resize the image to fit the screen if needed\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    scaling_factor = min(screen_width / img_width, screen_height / img_height)\n",
    "    if scaling_factor < 1.0:\n",
    "        img = cv2.resize(img, (int(img_width * scaling_factor), int(img_height * scaling_factor)))\n",
    "\n",
    "    # Optionally save the output image\n",
    "    if output_path:\n",
    "        cv2.imwrite(output_path, img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "363dc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_label_on_image(img, label, x, y, screen_width):\n",
    "    \"\"\"\n",
    "    Put a label on the image, adjusting its position if it goes off-screen.\n",
    "\n",
    "    Parameters:\n",
    "    - img (numpy.ndarray): Image on which to put the label.\n",
    "    - label (str): The text label to put on the image.\n",
    "    - x (int): X coordinate for label placement.\n",
    "    - y (int): Y coordinate for label placement.\n",
    "    - screen_width (int): Width of the screen to prevent overflow.\n",
    "    \"\"\"\n",
    "    font_scale = 0.5\n",
    "    font_thickness = 1\n",
    "    (label_width, label_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)\n",
    "\n",
    "    # Adjust label position if it goes off-screen\n",
    "    if x + label_width > screen_width:\n",
    "        x = screen_width - label_width - 10  # 10 pixels padding from the edge\n",
    "\n",
    "    cv2.rectangle(\n",
    "        img,\n",
    "        (x, y - label_height - baseline),\n",
    "        (x + label_width, y),\n",
    "        color=(0, 255, 0),\n",
    "        thickness=cv2.FILLED\n",
    "    )\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        label,\n",
    "        (x, y - baseline),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        font_scale,\n",
    "        (0, 0, 0),\n",
    "        thickness=font_thickness,\n",
    "        lineType=cv2.LINE_AA\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "add31f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1 objects:\n",
      "Class: arabica, Confidence: 0.67, BBox: (10, 0), (263, 167)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_image_path = 'lf4.jpg'  \n",
    "    output_image_path = 'test_output.jpg'\n",
    "\n",
    "    # Detect using the cleaf model with custom thresholds\n",
    "    result_img_cleaf = detect_objects(\n",
    "        input_image_path,\n",
    "        model_type='cleaf',\n",
    "        output_path='cleaf_detected.jpg',\n",
    "        conf_threshold=0.1,  # Adjust confidence threshold\n",
    "        iou_threshold=0.4    # Adjust IOU threshold\n",
    "    )\n",
    "\n",
    "    screen_width = 1920  # Set this to your screen width\n",
    "    screen_height = 1080  # Set this to your screen height\n",
    "\n",
    "    # Get image dimensions\n",
    "    img_height, img_width = result_img_cleaf.shape[:2]\n",
    "\n",
    "    # Calculate the scaling factor while maintaining aspect ratio\n",
    "    scaling_factor = min(screen_width / img_width, screen_height / img_height)\n",
    "\n",
    "    # Resize the image if it's larger than the screen\n",
    "    if scaling_factor < 1.0:\n",
    "        result_img_cleaf = cv2.resize(result_img_cleaf, (int(img_width * scaling_factor), int(img_height * scaling_factor)))\n",
    "\n",
    "    # Display the results using OpenCV\n",
    "    cv2.imshow('Cleaf Detection', result_img_cleaf)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "262d615e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 52 objects:\n",
      "Class: leaf_rust, Confidence: 0.78, BBox: (84, 104), (100, 122)\n",
      "Class: leaf_rust, Confidence: 0.76, BBox: (97, 37), (109, 47)\n",
      "Class: leaf_rust, Confidence: 0.76, BBox: (123, 111), (140, 127)\n",
      "Class: leaf_rust, Confidence: 0.71, BBox: (85, 40), (97, 50)\n",
      "Class: leaf_rust, Confidence: 0.69, BBox: (55, 146), (67, 154)\n",
      "Class: leaf_rust, Confidence: 0.69, BBox: (81, 130), (92, 139)\n",
      "Class: leaf_rust, Confidence: 0.69, BBox: (52, 65), (65, 77)\n",
      "Class: leaf_rust, Confidence: 0.69, BBox: (82, 146), (94, 154)\n",
      "Class: leaf_rust, Confidence: 0.68, BBox: (37, 56), (50, 68)\n",
      "Class: leaf_rust, Confidence: 0.66, BBox: (33, 121), (43, 131)\n",
      "Class: leaf_rust, Confidence: 0.66, BBox: (117, 81), (144, 101)\n",
      "Class: leaf_rust, Confidence: 0.65, BBox: (128, 30), (139, 40)\n",
      "Class: leaf_rust, Confidence: 0.65, BBox: (84, 50), (94, 59)\n",
      "Class: leaf_rust, Confidence: 0.64, BBox: (120, 7), (139, 18)\n",
      "Class: leaf_rust, Confidence: 0.64, BBox: (129, 50), (140, 62)\n",
      "Class: leaf_rust, Confidence: 0.64, BBox: (109, 98), (122, 108)\n",
      "Class: leaf_rust, Confidence: 0.60, BBox: (66, 46), (76, 55)\n",
      "Class: leaf_rust, Confidence: 0.59, BBox: (100, 101), (109, 110)\n",
      "Class: leaf_rust, Confidence: 0.59, BBox: (34, 81), (48, 100)\n",
      "Class: leaf_rust, Confidence: 0.58, BBox: (97, 56), (117, 71)\n",
      "Class: leaf_rust, Confidence: 0.57, BBox: (23, 95), (34, 106)\n",
      "Class: leaf_rust, Confidence: 0.57, BBox: (141, 68), (161, 90)\n",
      "Class: leaf_rust, Confidence: 0.55, BBox: (147, 93), (179, 126)\n",
      "Class: leaf_rust, Confidence: 0.55, BBox: (36, 109), (44, 118)\n",
      "Class: leaf_rust, Confidence: 0.54, BBox: (67, 57), (78, 67)\n",
      "Class: leaf_rust, Confidence: 0.51, BBox: (104, 21), (114, 30)\n",
      "Class: leaf_rust, Confidence: 0.50, BBox: (48, 110), (60, 123)\n",
      "Class: leaf_rust, Confidence: 0.48, BBox: (113, 130), (130, 142)\n",
      "Class: leaf_rust, Confidence: 0.48, BBox: (72, 24), (94, 37)\n",
      "Class: leaf_rust, Confidence: 0.46, BBox: (254, 125), (276, 153)\n",
      "Class: leaf_rust, Confidence: 0.44, BBox: (61, 54), (69, 62)\n",
      "Class: leaf_rust, Confidence: 0.41, BBox: (83, 24), (94, 33)\n",
      "Class: leaf_rust, Confidence: 0.41, BBox: (143, 127), (153, 135)\n",
      "Class: leaf_rust, Confidence: 0.40, BBox: (100, 137), (114, 149)\n",
      "Class: leaf_rust, Confidence: 0.39, BBox: (34, 81), (46, 89)\n",
      "Class: leaf_rust, Confidence: 0.37, BBox: (131, 76), (141, 85)\n",
      "Class: leaf_rust, Confidence: 0.37, BBox: (112, 25), (120, 33)\n",
      "Class: leaf_rust, Confidence: 0.37, BBox: (142, 12), (170, 32)\n",
      "Class: leaf_rust, Confidence: 0.33, BBox: (141, 80), (157, 90)\n",
      "Class: leaf_rust, Confidence: 0.30, BBox: (154, 93), (166, 109)\n",
      "Class: leaf_rust, Confidence: 0.29, BBox: (30, 137), (39, 146)\n",
      "Class: leaf_rust, Confidence: 0.27, BBox: (105, 22), (120, 33)\n",
      "Class: leaf_rust, Confidence: 0.26, BBox: (62, 47), (77, 64)\n",
      "Class: leaf_rust, Confidence: 0.24, BBox: (195, 91), (215, 113)\n",
      "Class: leaf_rust, Confidence: 0.21, BBox: (107, 47), (116, 56)\n",
      "Class: leaf_rust, Confidence: 0.19, BBox: (122, 160), (141, 177)\n",
      "Class: leaf_rust, Confidence: 0.17, BBox: (162, 71), (181, 80)\n",
      "Class: leaf_rust, Confidence: 0.15, BBox: (141, 68), (153, 79)\n",
      "Class: leaf_rust, Confidence: 0.15, BBox: (179, 79), (193, 91)\n",
      "Class: leaf_rust, Confidence: 0.15, BBox: (159, 48), (168, 57)\n",
      "Class: leaf_rust, Confidence: 0.12, BBox: (117, 81), (129, 89)\n",
      "Class: leaf_rust, Confidence: 0.12, BBox: (100, 130), (130, 149)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_image_path = 'lf4.jpg'  \n",
    "    output_image_path = 'test_output.jpg'\n",
    "\n",
    "    # Detect using the cleaf model with custom thresholds\n",
    "    result_img_cdisease = detect_objects(\n",
    "        input_image_path,\n",
    "        model_type='cdisease',\n",
    "        output_path='cleaf_detected.jpg',\n",
    "        conf_threshold=0.1,  # Adjust confidence threshold\n",
    "        iou_threshold=0.4    # Adjust IOU threshold\n",
    "    )\n",
    "    \n",
    "    screen_width = 1920  # Set this to your screen width\n",
    "    screen_height = 1080  # Set this to your screen height\n",
    "\n",
    "    # Get image dimensions\n",
    "    img_height, img_width = result_img_cdisease.shape[:2]\n",
    "\n",
    "    # Calculate the scaling factor while maintaining aspect ratio\n",
    "    scaling_factor = min(screen_width / img_width, screen_height / img_height)\n",
    "\n",
    "    # Resize the image if it's larger than the screen\n",
    "    if scaling_factor < 1.0:\n",
    "        result_img_cdisease = cv2.resize(result_img_cdisease, (int(img_width * scaling_factor), int(img_height * scaling_factor)))\n",
    "    \n",
    "    # Display the results using OpenCV (optional)\n",
    "    cv2.imshow('Cdisease Detection', result_img_cdisease)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a791688",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_image_path = 'lf.jpg'\n",
    "    output_image_path = 'test_output.jpg'\n",
    "\n",
    "    result_img = detect_and_classify_coffee_disease(\n",
    "        input_image_path,\n",
    "        output_path=output_image_path,\n",
    "        conf_threshold=0.1,\n",
    "        iou_threshold=0.4,\n",
    "        screen_width=1920,  # Your screen width\n",
    "        screen_height=1080  # Your screen height\n",
    "    )\n",
    "\n",
    "    # Display the results using OpenCV\n",
    "    cv2.imshow('Coffee Disease Detection', result_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13de327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
